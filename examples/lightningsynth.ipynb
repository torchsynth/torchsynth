{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"lightningsynth.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/github/torchsynth/torchsynth/blob/lightning-synth/examples/lightningsynth.ipynb\n",
    "\n",
    "# lightningsynth\n",
    "\n",
    "Profiling for our synth on GPUs\n",
    "\n",
    "Make sure you are on GPU runtime\n",
    "\n",
    "If this hasn't been merged to master yet, run:\n",
    "```\n",
    "!pip uninstall -y torchsynth\n",
    "!pip install git+https://github.com/torchsynth/torchsynth.git@lightning-synth\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y torchsynth\n",
    "!pip install git+https://github.com/torchsynth/torchsynth.git@lightning-synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "import torch.autograd.profiler as profiler\n",
    "import torch.tensor as tensor\n",
    "from torch import Tensor as T\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsynth.module\n",
    "from torchsynth.config import SynthConfig\n",
    "from torchsynth.synth import Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = torch.cuda.device_count()\n",
    "print(\"Usings %d gpus\" % gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this is the batch size for our synth!\n",
    "# i.e. this many synth sounds are generated at once\n",
    "# Not the batch size of the datasets\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncores = multiprocessing.cpu_count()\n",
    "print(f\"Using ncores {ncores} for generating batch numbers (low CPU usage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "class batch_idx_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, num_batches):\n",
    "        self.num_batches = num_batches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Add this to torchsynth API\n",
    "# see https://github.com/torchsynth/torchsynth/issues/154\n",
    "class TorchSynthCallback(pl.Callback):\n",
    "    def on_test_batch_end(\n",
    "        self,\n",
    "        trainer,\n",
    "        pl_module: pl.LightningModule,\n",
    "        outputs: Any,\n",
    "        batch: Any,\n",
    "        batch_idx: int,\n",
    "        dataloader_idx: int,\n",
    "    ) -> None:\n",
    "        assert batch.ndim == 1\n",
    "        _ = pl_module(batch_idx)\n",
    "        # I don't think the following is correct\n",
    "        # _ = torch.stack([pl_module(i) for i in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth1B = batch_idx_dataset(1024 * 1024 * 1024 // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(synth1B, num_workers=0, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice = Voice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = None\n",
    "if gpus == 0:\n",
    "    use_gpus = None\n",
    "    precision = 32\n",
    "else:\n",
    "    # specifies all available GPUs (if only one GPU is not occupied,\n",
    "    # auto_select_gpus=True uses one gpu)\n",
    "    use_gpus = -1\n",
    "    # Golden cables\n",
    "    #    # TODO: Change precision?\n",
    "    #    precision = 16\n",
    "    if gpus > 1:\n",
    "        accelerator = \"ddp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use deterministic?\n",
    "trainer = pl.Trainer(\n",
    "    precision=precision,\n",
    "    gpus=use_gpus,\n",
    "    auto_select_gpus=True,\n",
    "    accelerator=accelerator,\n",
    "    deterministic=synthconfig.reproducible,\n",
    "    max_epochs=0,\n",
    "    callbacks=[TorchSynthCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(voice, test_dataloaders=test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
