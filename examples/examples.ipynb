{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchsynth examples\n",
    "\n",
    "We walk through basic functionality of `torchsynth` in this Jupyter notebook.\n",
    "\n",
    "Just note that all ipd.Audio play widgets normalize the audio.\n",
    "\n",
    "If you're in Colab, remember to set the runtime to GPU.\n",
    "and get the latest torchsynth:\n",
    "\n",
    "```\n",
    "!pip install git+https://github.com/torchsynth/torchsynth.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iscolab():  # pragma: no cover\n",
    "    return \"google.colab\" in str(get_ipython())\n",
    "\n",
    "\n",
    "def isnotebook():  # pragma: no cover\n",
    "    try:\n",
    "        if iscolab():\n",
    "            return True\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == \"ZMQInteractiveShell\":\n",
    "            return True  # Jupyter notebook or qtconsole\n",
    "        elif shell == \"TerminalInteractiveShell\":\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False  # Probably standard Python interprete\n",
    "\n",
    "\n",
    "print(f\"isnotebook = {isnotebook()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if isnotebook():  # pragma: no cover\n",
    "    import IPython.display as ipd\n",
    "    import librosa\n",
    "    import librosa.display\n",
    "    import matplotlib.pyplot as plt\n",
    "    from IPython.core.display import display\n",
    "else:\n",
    "\n",
    "    class IPD:\n",
    "        def Audio(*args, **kwargs):\n",
    "            pass\n",
    "\n",
    "        def display(*args, **kwargs):\n",
    "            pass\n",
    "\n",
    "    ipd = IPD()\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "from torchsynth.config import SynthConfig\n",
    "from torchsynth.module import (\n",
    "    ADSR,\n",
    "    VCA,\n",
    "    ControlRateUpsample,\n",
    "    MonophonicKeyboard,\n",
    "    Noise,\n",
    "    SineVCO,\n",
    "    FmVCO,\n",
    ")\n",
    "from torchsynth.parameter import ModuleParameterRange\n",
    "\n",
    "# Determenistic seeds for replicable testing\n",
    "random.seed(0)\n",
    "numpy.random.seed(0)\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run examples on GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_plot(signal, sample_rate=44100, show=True):\n",
    "    if isnotebook():  # pragma: no cover\n",
    "        t = np.linspace(0, len(signal) / sample_rate, len(signal), endpoint=False)\n",
    "        plt.plot(t, signal)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        if show:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_plot(signal, sample_rate=44100):\n",
    "    if isnotebook():  # pragma: no cover\n",
    "        X = librosa.stft(signal)\n",
    "        Xdb = librosa.amplitude_to_db(abs(X))\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        librosa.display.specshow(Xdb, sr=sample_rate, x_axis=\"time\", y_axis=\"log\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Globals\n",
    "# We'll generate 2 sounds at once, 4 seconds each\n",
    "synthconfig = SynthConfig(\n",
    "    batch_size=2, reproducible=False, sample_rate=44100, buffer_size_seconds=4.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a few examples, we'll only generate one sound\n",
    "synthconfig1 = SynthConfig(\n",
    "    batch_size=1, reproducible=False, sample_rate=44100, buffer_size_seconds=4.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And a short one sound\n",
    "synthconfig1short = SynthConfig(\n",
    "    batch_size=1, reproducible=False, sample_rate=44100, buffer_size_seconds=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Envelope\n",
    "Our module is based on an ADSR envelope, standing for \"attack, decay, sustain,\n",
    "release,\" which is specified by four values:\n",
    "\n",
    "- a: the attack time, in seconds; the time it takes for the signal to ramp\n",
    "     from 0 to 1.\n",
    "- d: the decay time, in seconds; the time to 'decay' from a peak of 1 to a\n",
    "     sustain level.\n",
    "- s: the sustain level; a value between 0 and 1 that the envelope holds during\n",
    "a sustained note (**not a time value**).\n",
    "- r: the release time, in seconds; the time it takes the signal to decay from\n",
    "     the sustain value to 0.\n",
    "\n",
    "Envelopes are used to modulate a variety of signals; usually one of pitch,\n",
    "amplitude, or filter cutoff frequency. In this notebook we will use the same\n",
    "envelope to modulate several different audio parameters.\n",
    "\n",
    "### A note about note-on, note-off behaviour\n",
    "\n",
    "By default, this envelope reacts as if it was triggered with midi, for example\n",
    "playing a keyboard. Each midi event has a beginning and end: note-on, when you\n",
    "press the key down; and note-off, when you release the key. `note_on_duration`\n",
    "is the amount of time that the key is depressed. During the note-on, the\n",
    "envelope moves through the attack and decay sections of the envelope. This\n",
    "leads to musically-intuitive, but programatically-counterintuitive behaviour.\n",
    "\n",
    "Assume attack is 0.5 seconds, and decay is 0.5 seconds. If a note is held for\n",
    "0.75 seconds, the envelope won't traverse through the entire attack-and-decay\n",
    "phase (specifically, it will execute the entire attack, and 0.25 seconds of\n",
    "the decay).\n",
    "\n",
    "If this is confusing, don't worry about it. ADSR's do a lot of work behind the\n",
    "scenes to make the playing experience feel natural. Alternately, you may\n",
    "specify one-shot mode (see below), which is more typical of drum machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesis parameters.\n",
    "a = tensor([0.1, 0.2])\n",
    "d = tensor([0.1, 0.2])\n",
    "s = tensor([0.75, 0.8])\n",
    "r = tensor([0.5, 0.8])\n",
    "alpha = tensor([3.0, 4.0])\n",
    "note_on_duration = tensor([0.5, 1.5], device=device)\n",
    "\n",
    "# Envelope test\n",
    "adsr = ADSR(\n",
    "    attack=a,\n",
    "    decay=d,\n",
    "    sustain=s,\n",
    "    release=r,\n",
    "    alpha=alpha,\n",
    "    synthconfig=synthconfig,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "\n",
    "envelope = adsr(note_on_duration)\n",
    "time_plot(envelope.clone().detach().cpu().T, adsr.control_rate.item())\n",
    "print(adsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the l1 error between the two envelopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = torch.mean(torch.abs(envelope[0, :] - envelope[1, :]))\n",
    "print(\"Error =\", err)\n",
    "time_plot(torch.abs(envelope[0, :] - envelope[1, :]).detach().cpu().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### And here are the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err.backward(retain_graph=True)\n",
    "# for p in adsr.torchparameters:\n",
    "#    print(adsr.torchparameters[p].data.grad)\n",
    "#    print(f\"{p} grad1={adsr.torchparameters[p].data.grad} grad2={adsr.torchparameters[p].data.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating Random Envelopes**\n",
    "\n",
    "If we don't set parameters for an ADSR, then the parameters will be random when\n",
    "initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that module parameters are optional. If they are not provided,\n",
    "# they will be randomly initialized (like a typical neural network module)\n",
    "adsr = ADSR(synthconfig, device=device)\n",
    "envelope = adsr(note_on_duration)\n",
    "print(envelope.shape)\n",
    "time_plot(envelope.clone().detach().cpu().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can also use an optimizer to match the parameters of the two ADSRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer = torch.optim.Adam(list(adsr2.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "time_plot(envelope.detach().cpu(), adsr.sample_rate, show=False)\n",
    "time_plot(envelope2.detach().cpu(), adsr.sample_rate, show=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    envelope = adsr(note_on_duration)\n",
    "    envelope2 = adsr2(note_on_duration)\n",
    "    err = torch.mean(torch.abs(envelope - envelope2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    if i % 10 == 0:\n",
    "        ax.set_title(f\"Optimization Step {i} - Error: {err.item()}\")\n",
    "        ax.lines[0].set_ydata(envelope.detach().cpu())\n",
    "        ax.lines[1].set_ydata(envelope2.detach().cpu())\n",
    "        fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "    err.backward()\n",
    "    optimizer.step()\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oscillators\n",
    "\n",
    "There are several types of oscillators and sound generators available. Oscillators\n",
    "that can be controlled by an external signal are called voltage-coltrolled\n",
    "oscillators (VCOs) in the analog world and we adpot a similar approach here;\n",
    "oscillators accept an input control signal and produce audio output. We have a simple\n",
    "sine oscilator:`SineVCO`, a square/saw oscillator: `SquareSawVCO`, and an FM\n",
    "oscillator: `FmVCO`. There is also a white noise generator: `Noise`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sine VCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a Keyboard module\n",
    "keyboard = MonophonicKeyboard(\n",
    "    synthconfig, device, midi_f0=tensor([69.0, 50.0]), duration=note_on_duration\n",
    ")\n",
    "\n",
    "# Trigger the keyboard, which returns a midi_f0 and note duration\n",
    "midi_f0, duration = keyboard()\n",
    "\n",
    "# Instantiate the sine wave VCO with tuning set to zero\n",
    "sine_vco = SineVCO(\n",
    "    tuning=tensor([0.0, 0.0]),\n",
    "    synthconfig=synthconfig,\n",
    ").to(device)\n",
    "\n",
    "# Call the sine_vco with the midi_f0\n",
    "out = sine_vco(midi_f0)\n",
    "\n",
    "stft_plot(out[0].detach().cpu().numpy())\n",
    "ipd.display(ipd.Audio(out[0].detach().cpu().numpy(), rate=sine_vco.sample_rate.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VCOs have an optional pitch modulation argument that can be passed in during generation. Let's create a sine vco modulated with an envelope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a Keyboard module\n",
    "keyboard = MonophonicKeyboard(\n",
    "    synthconfig, device, midi_f0=tensor([69.0, 50.0]), duration=note_on_duration\n",
    ")\n",
    "\n",
    "# Reset envelope\n",
    "adsr = ADSR(\n",
    "    attack=a,\n",
    "    decay=d,\n",
    "    sustain=s,\n",
    "    release=r,\n",
    "    alpha=alpha,\n",
    "    synthconfig=synthconfig,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Trigger the keyboard, which returns a midi_f0 and note duration\n",
    "midi_f0, duration = keyboard()\n",
    "\n",
    "# Create an envelope -- modulation signals are computed at a lower\n",
    "# sampling rate and must be upsampled prior to feeding into audio\n",
    "# rate modules\n",
    "envelope = adsr(duration)\n",
    "upsample = ControlRateUpsample(synthconfig)\n",
    "envelope = upsample(envelope)\n",
    "\n",
    "# SineVCO test -- call to(device) instead of passing in device to constructor also works\n",
    "sine_vco = SineVCO(\n",
    "    tuning=tensor([0.0, 0.0]),\n",
    "    mod_depth=tensor([-12.0, 12.0]),\n",
    "    synthconfig=synthconfig,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "sine_out = sine_vco(midi_f0, envelope)\n",
    "\n",
    "stft_plot(sine_out[0].detach().cpu().numpy())\n",
    "ipd.display(\n",
    "    ipd.Audio(sine_out[0].detach().cpu().numpy(), rate=sine_vco.sample_rate.item())\n",
    ")\n",
    "stft_plot(sine_out[1].detach().cpu().numpy())\n",
    "ipd.display(\n",
    "    ipd.Audio(sine_out[1].detach().cpu().numpy(), rate=sine_vco.sample_rate.item())\n",
    ")\n",
    "\n",
    "# We can use auraloss instead of raw waveform loss. This is just\n",
    "# to show that gradient computations occur\n",
    "err = torch.mean(torch.abs(sine_out[0] - sine_out[1]))\n",
    "print(\"Error =\", err)\n",
    "time_plot(torch.abs(sine_out[0] - sine_out[1]).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err.backward(retain_graph=True)\n",
    "# for p in sine_vco.torchparameters:\n",
    "#    print(f\"{p} grad1={sine_vco.torchparameters[p].grad.item()} grad2={sine_vco2.torchparameters[p].grad.item()}\")\n",
    "## Both SineVCOs use the sample envelope\n",
    "# for p in adsr.torchparameters:\n",
    "#    print(f\"{p} grad={adsr.torchparameters[p].grad.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SquareSaw Oscillator\n",
    "\n",
    "Check this out, it's a square / saw oscillator. Use the shape parameter to\n",
    "interpolate between a square wave (shape = 0) and a sawtooth wave (shape = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsynth.module import SquareSawVCO\n",
    "\n",
    "keyboard = MonophonicKeyboard(synthconfig, device, midi_f0=tensor([30.0, 30.0])).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "square_saw = SquareSawVCO(\n",
    "    tuning=tensor([0.0, 0.0]),\n",
    "    mod_depth=tensor([0.0, 0.0]),\n",
    "    shape=tensor([0.0, 1.0]),\n",
    "    synthconfig=synthconfig,\n",
    "    device=device,\n",
    ")\n",
    "env2 = torch.zeros([2, square_saw.buffer_size], device=device)\n",
    "\n",
    "square_saw_out = square_saw(keyboard.p(\"midi_f0\"), env2)\n",
    "stft_plot(square_saw_out[0].cpu().detach().numpy())\n",
    "ipd.display(\n",
    "    ipd.Audio(\n",
    "        square_saw_out[0].cpu().detach().numpy(), rate=square_saw.sample_rate.item()\n",
    "    )\n",
    ")\n",
    "stft_plot(square_saw_out[1].cpu().detach().numpy())\n",
    "ipd.display(\n",
    "    ipd.Audio(\n",
    "        square_saw_out[1].cpu().detach().numpy(), rate=square_saw.sample_rate.item()\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "err = torch.mean(torch.abs(square_saw_out[0] - square_saw_out[1]))\n",
    "print(err)\n",
    "# err.backward(retain_graph=True)\n",
    "# for p in square_saw.torchparameters:\n",
    "#    print(f\"{p} grad1={square_saw.torchparameters[p][0].grad.item()} grad2={square_saw.torchparameters[p][1].grad.item()}\")\n",
    "\n",
    "# ### VCA\n",
    "#\n",
    "# Notice that this sound is rather clicky. We'll add an envelope to the\n",
    "# amplitude to smooth it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vca = VCA(synthconfig, device=device)\n",
    "test_output = vca(envelope, sine_out)\n",
    "\n",
    "time_plot(test_output[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FM Synthesis\n",
    "\n",
    "What about FM? You bet. Use the `FmVCO` class. It accepts any audio input.\n",
    "\n",
    "Just a note that, as in classic FM synthesis, you're dealing with a complex\n",
    "architecture of modulators. Each 'operator ' has its own pitch envelope, and\n",
    "amplitude envelope. The 'amplitude' envelope of an operator is really the\n",
    "*modulation depth* of the oscillator it operates on. So in the example below,\n",
    "we're using an ADSR to shape the depth of the *operator*, and this affects\n",
    "the modulation depth of the resultant signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FmVCO test\n",
    "\n",
    "keyboard = MonophonicKeyboard(\n",
    "    synthconfig, device=device, midi_f0=tensor([50.0, 50.0])\n",
    ").to(device)\n",
    "\n",
    "# Make steady-pitched sine (no pitch modulation).\n",
    "sine_operator = SineVCO(\n",
    "    tuning=tensor([0.0, 0.0]),\n",
    "    mod_depth=tensor([0.0, 5.0]),\n",
    "    synthconfig=synthconfig,\n",
    "    device=device,\n",
    ")\n",
    "operator_out = sine_operator(keyboard.p(\"midi_f0\"), envelope)\n",
    "\n",
    "# Shape the modulation depth.\n",
    "operator_out = vca(envelope, operator_out)\n",
    "\n",
    "# Feed into FM oscillator as modulator signal.\n",
    "fm_vco = FmVCO(\n",
    "    tuning=tensor([0.0, 0.0]),\n",
    "    mod_depth=tensor([2.0, 5.0]),\n",
    "    synthconfig=synthconfig,\n",
    "    device=device,\n",
    ")\n",
    "fm_out = fm_vco(keyboard.p(\"midi_f0\"), operator_out)\n",
    "\n",
    "stft_plot(fm_out[0].cpu().detach().numpy())\n",
    "ipd.display(ipd.Audio(fm_out[0].cpu().detach().numpy(), rate=fm_vco.sample_rate.item()))\n",
    "\n",
    "stft_plot(fm_out[1].cpu().detach().numpy())\n",
    "ipd.display(ipd.Audio(fm_out[1].cpu().detach().numpy(), rate=fm_vco.sample_rate.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise\n",
    "\n",
    "The noise generator creates white noise the same length as the SynthModule buffer length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Noise(synthconfig, seed=42, device=device)\n",
    "out = noise()\n",
    "\n",
    "stft_plot(out[0].detach().cpu().numpy())\n",
    "ipd.Audio(out[0].detach().cpu().numpy(), rate=noise.sample_rate.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsynth.module import AudioMixer\n",
    "\n",
    "env = torch.zeros((synthconfig.batch_size, synthconfig.buffer_size), device=device)\n",
    "\n",
    "keyboard = MonophonicKeyboard(synthconfig, device=device)\n",
    "sine = SineVCO(synthconfig, device=device)\n",
    "square_saw = SquareSawVCO(synthconfig, device=device)\n",
    "noise = Noise(synthconfig, seed=123, device=device)\n",
    "\n",
    "midi_f0, note_on_duration = keyboard()\n",
    "sine_out = sine(midi_f0, env)\n",
    "sqr_out = square_saw(midi_f0, env)\n",
    "noise_out = noise()\n",
    "\n",
    "mixer = AudioMixer(synthconfig, 3, curves=[1.0, 1.0, 0.25]).to(device)\n",
    "output = mixer(sine_out, sqr_out, noise_out)\n",
    "\n",
    "ipd.Audio(out[0].cpu().detach().numpy(), rate=mixer.sample_rate.item(), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixer params are set in dB\n",
    "mixer.set_parameter(\"level0\", tensor([0.25, 0.25], device=device))\n",
    "mixer.set_parameter(\"level1\", tensor([0.25, 0.25], device=device))\n",
    "mixer.set_parameter(\"level2\", tensor([0.125, 0.125], device=device))\n",
    "\n",
    "out = mixer(sine_out, sqr_out, noise_out)\n",
    "ipd.Audio(out[0].cpu().detach().numpy(), rate=mixer.sample_rate.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modulation\n",
    "\n",
    "Besides envelopes, LFOs can be used to modulate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsynth.module import LFO, ModulationMixer\n",
    "\n",
    "lfo = LFO(synthconfig, device=device)\n",
    "lfo.set_parameter(\"mod_depth\", tensor([10.0, 0.0]))\n",
    "lfo.set_parameter(\"frequency\", tensor([1.0, 1.0]))\n",
    "out = lfo()\n",
    "\n",
    "# LFOs can also be triggered with a modulation signal that\n",
    "# controls the frequency over time\n",
    "\n",
    "# Trigger the keyboard, which returns a midi_f0 and note duration\n",
    "midi_f0, duration = keyboard()\n",
    "\n",
    "adsr = ADSR(synthconfig=synthconfig, device=device)\n",
    "envelope = adsr(duration)\n",
    "\n",
    "lfo2 = LFO(synthconfig, device=device)\n",
    "out2 = lfo2(envelope)\n",
    "\n",
    "time_plot(out[0].detach().cpu().numpy(), sample_rate=lfo.control_rate.item())\n",
    "time_plot(out2[0].detach().cpu().numpy(), sample_rate=lfo.control_rate.item())\n",
    "\n",
    "# A modulation mixer can be used to mix a modulation sources together\n",
    "# and maintain a 0 to 1 amplitude range\n",
    "mixer = ModulationMixer(synthconfig=synthconfig, device=device, n_input=2, n_output=1)\n",
    "mods_mixed = mixer(out, out2)\n",
    "\n",
    "print(f\"Mixed: LFO 1:{mixer.p('0->0')[0]:.2}, LFO 2: {mixer.p('1->0')[0]:.2}\")\n",
    "time_plot(mods_mixed[0][0].detach().cpu().numpy(), sample_rate=lfo.control_rate.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice Module\n",
    "\n",
    "Alternately, you can just use the Voice class that composes all these modules\n",
    "together automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsynth.synth import Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice1 = Voice(synthconfig=synthconfig1).to(device)\n",
    "voice1.set_parameters(\n",
    "    {\n",
    "        (\"keyboard\", \"midi_f0\"): tensor([69.0]),\n",
    "        (\"keyboard\", \"duration\"): tensor([1.0]),\n",
    "        (\"vco_1\", \"tuning\"): tensor([0.0]),\n",
    "        (\"vco_1\", \"mod_depth\"): tensor([12.0]),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "All Synths in torchsynth return a triple containing the audio\n",
    "output, parameters for this sound, as well as a tensor of bools indicating whether\n",
    "each sound can be considered a training item. The purpose of this multi-modal output\n",
    "is to support machine learning researchers in creating large-scale reproducible audio\n",
    "datasets consisting of both training and testing samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* If the synth is not in reproducible mode then the test batch variable will\n",
    "be None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "audio_out, parameters, is_train = voice1()\n",
    "print(f\"Audio output: \\n{audio_out}\\n\")\n",
    "print(f\"Parameters used to create audio: \\n{parameters}\\n\")\n",
    "print(f\"Is test: \\n{is_train}\\n\")\n",
    "\n",
    "stft_plot(audio_out.cpu().view(-1).detach().numpy())\n",
    "ipd.Audio(audio_out.cpu().detach().numpy(), rate=voice1.sample_rate.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Additionally, the Voice class can take two oscillators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "voice2 = Voice(synthconfig=synthconfig1).to(device)\n",
    "voice2.set_parameters(\n",
    "    {\n",
    "        (\"keyboard\", \"midi_f0\"): tensor([40.0]),\n",
    "        (\"keyboard\", \"duration\"): tensor([3.0]),\n",
    "        (\"vco_1\", \"tuning\"): tensor([19.0]),\n",
    "        (\"vco_1\", \"mod_depth\"): tensor([24.0]),\n",
    "        (\"vco_2\", \"tuning\"): tensor([0.0]),\n",
    "        (\"vco_2\", \"mod_depth\"): tensor([12.0]),\n",
    "        (\"vco_2\", \"shape\"): tensor([1.0]),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Only grab the audio output from this voice\n",
    "voice_out2, _, _ = voice2()\n",
    "stft_plot(voice_out2.cpu().view(-1).detach().numpy())\n",
    "ipd.Audio(voice_out2.cpu().detach().numpy(), rate=voice2.sample_rate.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test gradients on entire voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = torch.mean(torch.abs(audio_out - voice_out2))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random synths\n",
    "\n",
    "Let's generate some random synths in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthconfig16 = SynthConfig(\n",
    "    batch_size=16, reproducible=False, sample_rate=44100, buffer_size_seconds=4\n",
    ")\n",
    "voice = Voice(synthconfig=synthconfig16).to(device)\n",
    "voice_out, _, _ = voice()\n",
    "for i in range(synthconfig16.batch_size):\n",
    "    stft_plot(voice_out[i].cpu().view(-1).detach().numpy())\n",
    "    ipd.display(\n",
    "        ipd.Audio(voice_out[i].cpu().detach().numpy(), rate=voice.sample_rate.item())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters can be set and frozen before randomization as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice.unfreeze_all_parameters()\n",
    "voice.set_parameters(\n",
    "    {\n",
    "        (\"keyboard\", \"midi_f0\"): tensor([42.0] * voice.batch_size),\n",
    "        (\"keyboard\", \"duration\"): tensor([3.0] * voice.batch_size),\n",
    "        (\"vco_1\", \"tuning\"): tensor([0.0] * voice.batch_size),\n",
    "        (\"vco_2\", \"tuning\"): tensor([0.0] * voice.batch_size),\n",
    "    },\n",
    "    freeze=True,\n",
    ")\n",
    "\n",
    "voice_out, _, _ = voice()\n",
    "for i in range(synthconfig16.batch_size):\n",
    "    stft_plot(voice_out[i].cpu().view(-1).detach().numpy())\n",
    "    ipd.display(\n",
    "        ipd.Audio(voice_out[i].cpu().detach().numpy(), rate=voice.sample_rate.item())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters\n",
    "\n",
    "# All synth modules and synth classes have named parameters which can be quered\n",
    "# and updated. Let's look at the parameters for the Voice we just created.\n",
    "for n in voice1.get_parameter_names():\n",
    "    print(f\"{n:40}\")\n",
    "\n",
    "# Parameters are passed into SynthModules during creation with an initial value and a parameter range. The parameter range is a human readable range of values, for example MIDI note numbers from 1-127 for a VCO. These values are stored in a normalized range between 0 and 1. Parameters can be accessed and set using either ranges with specific methods.\n",
    "#\n",
    "# Parameters of individual modules can be accessed in several ways:\n",
    "\n",
    "# Get the full ModuleParameter object by name from the module\n",
    "print(voice1.vco_1.get_parameter(\"tuning\"))\n",
    "\n",
    "# Access the value as a Tensor in the full value human range\n",
    "print(voice1.vco_1.p(\"tuning\"))\n",
    "\n",
    "# Access the value as a float in the range from 0 to 1\n",
    "print(voice1.vco_1.get_parameter_0to1(\"tuning\"))\n",
    "\n",
    "# Parameters of individual modules can also be set using the human range or a normalized range between 0 and 1\n",
    "\n",
    "# Set the vco pitch using the human range, which is MIDI note number\n",
    "voice1.vco_1.set_parameter(\"tuning\", tensor([12.0]))\n",
    "print(voice1.vco_1.p(\"tuning\"))\n",
    "\n",
    "# Set the vco pitch using a normalized range between 0 and 1\n",
    "voice1.vco_1.set_parameter_0to1(\"tuning\", tensor([0.5]))\n",
    "print(voice1.vco_1.p(\"tuning\"))\n",
    "\n",
    "# #### Parameter Ranges\n",
    "#\n",
    "# Conversion between [0,1] range and a human range is handled by `ModuleParameterRange`. The conversion from [0,1] can be shaped by specifying a curve. Curve values less than 1 put more emphasis on lower values in the human range and curve values greater than 1 put more emphasis on larger values in the human range. A curve of 1 is a linear relationship between the two ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and setting raw parameter values\n",
    "\n",
    "Parameters in synths can be retrieved and set using torch tensors. The shape of the tensor returned from `get_raw_parameter_values()` is `(batch_size, num_parameters)`.\n",
    "\n",
    "Parameters values can also be set directly all at once by passing in a tensor with the same shape `(batch_size, num_parameters)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all parameters\n",
    "param_values = voice.get_raw_parameter_values()\n",
    "print(param_values.shape)\n",
    "print(param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all parameters from a tensor\n",
    "random_params = torch.rand_like(param_values)\n",
    "voice.set_raw_parameter_values(random_params)\n",
    "\n",
    "new_param_values = voice.get_raw_parameter_values()\n",
    "print(new_param_values.shape)\n",
    "print(new_param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ModuleParameterRange with scaling of a range from 0-127\n",
    "param_range_exp = ModuleParameterRange(0.0, 127.0, curve=0.5)\n",
    "param_range_lin = ModuleParameterRange(0.0, 127.0, curve=1.0)\n",
    "param_range_log = ModuleParameterRange(0.0, 127.0, curve=2.0)\n",
    "\n",
    "# Linearly spaced values from 0.0 1.0\n",
    "param_values = torch.linspace(0.0, 1.0, 100)\n",
    "\n",
    "if isnotebook():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "    axes[0].plot(param_values, param_range_exp.from_0to1(param_values))\n",
    "    axes[0].set_title(\"Exponential Scaling\")\n",
    "\n",
    "    axes[1].plot(param_values, param_range_lin.from_0to1(param_values))\n",
    "    axes[1].set_title(\"Linear Scaling\")\n",
    "\n",
    "    axes[2].plot(param_values, param_range_log.from_0to1(param_values))\n",
    "    axes[2].set_title(\"Logarithmic Scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModuleParameterRange with symmetric scaling of a range from -127 to 127\n",
    "param_range_exp = ModuleParameterRange(-127.0, 127.0, curve=0.5, symmetric=True)\n",
    "param_range_log = ModuleParameterRange(-127.0, 127.0, curve=2.0, symmetric=True)\n",
    "\n",
    "# Linearly spaced values from 0.0 1.0\n",
    "param_values = torch.linspace(0.0, 1.0, 100)\n",
    "\n",
    "if isnotebook():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "    axes[0].plot(param_values, param_range_exp.from_0to1(param_values))\n",
    "    axes[0].set_title(\"Exponential Scaling\")\n",
    "\n",
    "    axes[1].plot(param_values, param_range_log.from_0to1(param_values))\n",
    "    axes[1].set_title(\"Logarithmic Scaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "ParameterRanges are considered hyperparameters in torchsynth and can be viewed and modified through a Synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all hyperparameters\n",
    "voice1.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a specific hyperparameter\n",
    "voice1.set_hyperparameter((\"keyboard\", \"midi_f0\", \"curve\"), 0.1)\n",
    "print(voice1.hyperparameters[(\"keyboard\", \"midi_f0\", \"curve\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nebulae\n",
    "\n",
    "Different hyperparameter settings cause the parameters of a synth to be sampled in a\n",
    "different way when generating random synths. We call these different versions of the\n",
    "same synth different nebula. For example, here is the Voice loaded with the Drum\n",
    "nebula, which is more likely to produce sounds that are similar synth drum hits\n",
    "during random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthconfig16 = SynthConfig(\n",
    "    batch_size=16, reproducible=False, sample_rate=44100, buffer_size_seconds=4\n",
    ")\n",
    "voice = Voice(synthconfig=synthconfig16, nebula=\"drum\").to(device)\n",
    "voice_out, _, _ = voice()\n",
    "for i in range(synthconfig16.batch_size):\n",
    "    stft_plot(voice_out[i].cpu().view(-1).detach().numpy())\n",
    "    ipd.display(\n",
    "        ipd.Audio(voice_out[i].cpu().detach().numpy(), rate=voice.sample_rate.item())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
