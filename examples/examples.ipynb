{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchsynth examples\n",
    "\n",
    "We walk through basic functionality of `torchsynth` in this Jupyter notebook.\n",
    "\n",
    "Just note that all ipd.Audio play widgets normalize the audio.\n",
    "\n",
    "If you're in Colab, remember to set the runtime to GPU.\n",
    "and get the latest torchsynth:\n",
    "\n",
    "```\n",
    "!pip install git+https://github.com/turian/torchsynth.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iscolab():  # pragma: no cover\n",
    "    return \"google.colab\" in str(get_ipython())\n",
    "\n",
    "\n",
    "def isnotebook():  # pragma: no cover\n",
    "    try:\n",
    "        if iscolab():\n",
    "            return True\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == \"ZMQInteractiveShell\":\n",
    "            return True  # Jupyter notebook or qtconsole\n",
    "        elif shell == \"TerminalInteractiveShell\":\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False  # Probably standard Python interprete\n",
    "\n",
    "\n",
    "print(f\"isnotebook = {isnotebook()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if isnotebook():  # pragma: no cover\n",
    "    import IPython.display as ipd\n",
    "    import librosa\n",
    "    import librosa.display\n",
    "    import matplotlib.pyplot as plt\n",
    "    from IPython.core.display import display\n",
    "else:\n",
    "\n",
    "    class IPD:\n",
    "        def Audio(*args, **kwargs):\n",
    "            pass\n",
    "\n",
    "        def display(*args, **kwargs):\n",
    "            pass\n",
    "\n",
    "    ipd = IPD()\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import torch.fft\n",
    "import torch.tensor as tensor\n",
    "from torch import Tensor as T\n",
    "\n",
    "from torchsynth.default import DEFAULT_BUFFER_SIZE, DEFAULT_SAMPLE_RATE\n",
    "from torchsynth.config import SynthConfig\n",
    "from torchsynth.module import (\n",
    "    ADSR,\n",
    "    VCA,\n",
    "    ControlRateUpsample,\n",
    "    MonophonicKeyboard,\n",
    "    Noise,\n",
    "    SineVCO,\n",
    "    TorchFmVCO,\n",
    ")\n",
    "from torchsynth.parameter import ModuleParameterRange\n",
    "\n",
    "# Determenistic seeds for replicable testing\n",
    "random.seed(0)\n",
    "numpy.random.seed(0)\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run examples on GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_plot(signal, sample_rate=DEFAULT_SAMPLE_RATE, show=True):\n",
    "    if isnotebook():  # pragma: no cover\n",
    "        t = np.linspace(0, len(signal) / sample_rate, len(signal), endpoint=False)\n",
    "        plt.plot(t, signal)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        if show:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_plot(signal, sample_rate=DEFAULT_SAMPLE_RATE):\n",
    "    if isnotebook():  # pragma: no cover\n",
    "        X = librosa.stft(signal)\n",
    "        Xdb = librosa.amplitude_to_db(abs(X))\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        librosa.display.specshow(Xdb, sr=sample_rate, x_axis=\"time\", y_axis=\"log\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Globals\n",
    "# We'll generate 2 sounds at once, 4 seconds each\n",
    "synthconfig = SynthConfig(\n",
    "    batch_size=tensor(2), sample_rate=tensor(44100), buffer_size=tensor(4 * 44100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a few examples, we'll only generate one sound\n",
    "synthconfig1 = SynthConfig(\n",
    "    batch_size=tensor(1), sample_rate=tensor(44100), buffer_size=tensor(4 * 44100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And a short one sound\n",
    "synthconfig1short = SynthConfig(\n",
    "    batch_size=tensor(1), sample_rate=tensor(44100), buffer_size=tensor(4096)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Envelope\n",
    "Our module is based on an ADSR envelope, standing for \"attack, decay, sustain,\n",
    "release,\" which is specified by four values:\n",
    "\n",
    "- a: the attack time, in seconds; the time it takes for the signal to ramp\n",
    "     from 0 to 1.\n",
    "- d: the decay time, in seconds; the time to 'decay' from a peak of 1 to a\n",
    "     sustain level.\n",
    "- s: the sustain level; a value between 0 and 1 that the envelope holds during\n",
    "a sustained note (**not a time value**).\n",
    "- r: the release time, in seconds; the time it takes the signal to decay from\n",
    "     the sustain value to 0.\n",
    "\n",
    "Envelopes are used to modulate a variety of signals; usually one of pitch,\n",
    "amplitude, or filter cutoff frequency. In this notebook we will use the same\n",
    "envelope to modulate several different audio parameters.\n",
    "\n",
    "### A note about note-on, note-off behaviour\n",
    "\n",
    "By default, this envelope reacts as if it was triggered with midi, for example\n",
    "playing a keyboard. Each midi event has a beginning and end: note-on, when you\n",
    "press the key down; and note-off, when you release the key. `note_on_duration`\n",
    "is the amount of time that the key is depressed. During the note-on, the\n",
    "envelope moves through the attack and decay sections of the envelope. This\n",
    "leads to musically-intuitive, but programatically-counterintuitive behaviour.\n",
    "\n",
    "Assume attack is 0.5 seconds, and decay is 0.5 seconds. If a note is held for\n",
    "0.75 seconds, the envelope won't traverse through the entire attack-and-decay\n",
    "phase (specifically, it will execute the entire attack, and 0.25 seconds of\n",
    "the decay).\n",
    "\n",
    "If this is confusing, don't worry about it. ADSR's do a lot of work behind the\n",
    "scenes to make the playing experience feel natural. Alternately, you may\n",
    "specify one-shot mode (see below), which is more typical of drum machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesis parameters.\n",
    "a = tensor([0.1, 0.2])\n",
    "d = tensor([0.1, 0.2])\n",
    "s = tensor([0.75, 0.8])\n",
    "r = tensor([0.5, 0.8])\n",
    "alpha = tensor([3.0, 4.0])\n",
    "note_on_duration = tensor([0.5, 1.5], device=device)\n",
    "\n",
    "# Envelope test\n",
    "adsr = ADSR(\n",
    "    attack=a,\n",
    "    decay=d,\n",
    "    sustain=s,\n",
    "    release=r,\n",
    "    alpha=alpha,\n",
    "    synthconfig=synthconfig,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "\n",
    "envelope = adsr(note_on_duration)\n",
    "time_plot(envelope.clone().detach().cpu().T, adsr.control_rate.item())\n",
    "print(adsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the l1 error between the two envelopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = torch.mean(torch.abs(envelope[0, :] - envelope[1, :]))\n",
    "print(\"Error =\", err)\n",
    "time_plot(torch.abs(envelope[0, :] - envelope[1, :]).detach().cpu().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### And here are the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err.backward(retain_graph=True)\n",
    "# for p in adsr.torchparameters:\n",
    "#    print(adsr.torchparameters[p].data.grad)\n",
    "#    print(f\"{p} grad1={adsr.torchparameters[p].data.grad} grad2={adsr.torchparameters[p].data.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating Random Envelopes**\n",
    "\n",
    "If we don't set parameters for an ADSR, then the parameters will be random when\n",
    "initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that module parameters are optional. If they are not provided,\n",
    "# they will be randomly initialized (like a typical neural network module)\n",
    "adsr = ADSR(synthconfig, device=device)\n",
    "envelope = adsr(note_on_duration)\n",
    "print(envelope.shape)\n",
    "time_plot(envelope.clone().detach().cpu().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can also use an optimizer to match the parameters of the two ADSRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer = torch.optim.Adam(list(adsr2.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "time_plot(envelope.detach().cpu(), adsr.sample_rate, show=False)\n",
    "time_plot(envelope2.detach().cpu(), adsr.sample_rate, show=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    envelope = adsr(note_on_duration)\n",
    "    envelope2 = adsr2(note_on_duration)\n",
    "    err = torch.mean(torch.abs(envelope - envelope2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    if i % 10 == 0:\n",
    "        ax.set_title(f\"Optimization Step {i} - Error: {err.item()}\")\n",
    "        ax.lines[0].set_ydata(envelope.detach().cpu())\n",
    "        ax.lines[1].set_ydata(envelope2.detach().cpu())\n",
    "        fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "    err.backward()\n",
    "    optimizer.step()\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oscillators\n",
    "\n",
    "There are several types of oscillators and sound generators available. Oscillators that can be controlled by an external signal are called voltage-coltrolled oscillators (VCOs) in the analog world and we adpot a similar approach here; oscillators accept an input control signal and produce audio output. We have a simple sine oscilator:`SineVCO`, a square/saw oscillator: `SquareSawVCO`, and an FM oscillator: `TorchFmVCO`. There is also a white noise generator: `Noise`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Set up a Keyboard module\n",
    "keyboard = MonophonicKeyboard(\n",
    "    synthconfig, device, midi_f0=tensor([69.0, 50.0]), duration=note_on_duration\n",
    ")\n",
    "\n",
    "# Reset envelope\n",
    "adsr = ADSR(\n",
    "    attack=a,\n",
    "    decay=d,\n",
    "    sustain=s,\n",
    "    release=r,\n",
    "    alpha=alpha,\n",
    "    synthconfig=synthconfig,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Trigger the keyboard, which returns a midi_f0 and note duration\n",
    "midi_f0, duration = keyboard()\n",
    "\n",
    "# Create an envelope -- modulation signals are computed at a lower\n",
    "# sampling rate and must be upsampled prior to feeding into audio\n",
    "# rate modules\n",
    "envelope = adsr(duration)\n",
    "upsample = ControlRateUpsample(synthconfig)\n",
    "envelope = upsample(envelope)\n",
    "\n",
    "# SineVCO test -- call to(device) instead of passing in device to constructor also works\n",
    "sine_vco = SineVCO(\n",
    "    tuning=tensor([0.0, 0.0]),\n",
    "    mod_depth=tensor([-12.0, 12.0]),\n",
    "    synthconfig=synthconfig,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "sine_out = sine_vco(midi_f0, envelope)\n",
    "\n",
    "stft_plot(sine_out[0].detach().cpu().numpy())\n",
    "ipd.display(\n",
    "    ipd.Audio(sine_out[0].detach().cpu().numpy(), rate=sine_vco.sample_rate.item())\n",
    ")\n",
    "stft_plot(sine_out[1].detach().cpu().numpy())\n",
    "ipd.display(\n",
    "    ipd.Audio(sine_out[1].detach().cpu().numpy(), rate=sine_vco.sample_rate.item())\n",
    ")\n",
    "\n",
    "# We can use auraloss instead of raw waveform loss. This is just\n",
    "# to show that gradient computations occur\n",
    "err = torch.mean(torch.abs(sine_out[0] - sine_out[1]))\n",
    "print(\"Error =\", err)\n",
    "time_plot(torch.abs(sine_out[0] - sine_out[1]).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err.backward(retain_graph=True)\n",
    "# for p in sine_vco.torchparameters:\n",
    "#    print(f\"{p} grad1={sine_vco.torchparameters[p].grad.item()} grad2={sine_vco2.torchparameters[p].grad.item()}\")\n",
    "## Both SineVCOs use the sample envelope\n",
    "# for p in adsr.torchparameters:\n",
    "#    print(f\"{p} grad={adsr.torchparameters[p].grad.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SquareSaw Oscillator\n",
    "\n",
    "Check this out, it's a square / saw oscillator. Use the shape parameter to\n",
    "interpolate between a square wave (shape = 0) and a sawtooth wave (shape = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsynth.module import SquareSawVCO\n",
    "\n",
    "keyboard = MonophonicKeyboard(synthconfig, device, midi_f0=tensor([30.0, 30.0])).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "square_saw = SquareSawVCO(\n",
    "    tuning=tensor([0.0, 0.0]),\n",
    "    mod_depth=tensor([0.0, 0.0]),\n",
    "    shape=tensor([0.0, 1.0]),\n",
    "    synthconfig=synthconfig,\n",
    "    device=device,\n",
    ")\n",
    "env2 = torch.zeros([2, square_saw.buffer_size], device=device)\n",
    "\n",
    "square_saw_out = square_saw(keyboard.p(\"midi_f0\"), env2)\n",
    "stft_plot(square_saw_out[0].cpu().detach().numpy())\n",
    "ipd.display(\n",
    "    ipd.Audio(\n",
    "        square_saw_out[0].cpu().detach().numpy(), rate=square_saw.sample_rate.item()\n",
    "    )\n",
    ")\n",
    "stft_plot(square_saw_out[1].cpu().detach().numpy())\n",
    "ipd.display(\n",
    "    ipd.Audio(\n",
    "        square_saw_out[1].cpu().detach().numpy(), rate=square_saw.sample_rate.item()\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "err = torch.mean(torch.abs(square_saw_out[0] - square_saw_out[1]))\n",
    "print(err)\n",
    "# err.backward(retain_graph=True)\n",
    "# for p in square_saw.torchparameters:\n",
    "#    print(f\"{p} grad1={square_saw.torchparameters[p][0].grad.item()} grad2={square_saw.torchparameters[p][1].grad.item()}\")\n",
    "\n",
    "# ### VCA\n",
    "#\n",
    "# Notice that this sound is rather clicky. We'll add an envelope to the\n",
    "# amplitude to smooth it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vca = VCA(synthconfig, device=device)\n",
    "test_output = vca(envelope, sine_out)\n",
    "\n",
    "time_plot(test_output[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FM Synthesis\n",
    "\n",
    "What about FM? You bet. Use the `TorchFmVCO` class. It accepts any audio input.\n",
    "\n",
    "Just a note that, as in classic FM synthesis, you're dealing with a complex architecture of modulators. Each 'operator ' has its own pitch envelope, and amplitude envelope. The 'amplitude' envelope of an operator is really the *modulation depth* of the oscillator it operates on. So in the example below, we're using an ADSR to shape the depth of the *operator*, and this affects the modulation depth of the resultant signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FmVCO test\n",
    "\n",
    "keyboard = MonophonicKeyboard(\n",
    "    synthconfig, device=device, midi_f0=tensor([50.0, 50.0])\n",
    ").to(device)\n",
    "\n",
    "# Make steady-pitched sine (no pitch modulation).\n",
    "sine_operator = SineVCO(\n",
    "    tuning=tensor([0.0, 0.0]),\n",
    "    mod_depth=tensor([0.0, 5.0]),\n",
    "    synthconfig=synthconfig,\n",
    "    device=device,\n",
    ")\n",
    "operator_out = sine_operator(keyboard.p(\"midi_f0\"), envelope)\n",
    "\n",
    "# Shape the modulation depth.\n",
    "operator_out = vca(envelope, operator_out)\n",
    "\n",
    "# Feed into FM oscillator as modulator signal.\n",
    "fm_vco = TorchFmVCO(\n",
    "    tuning=tensor([0.0, 0.0]),\n",
    "    mod_depth=tensor([2.0, 5.0]),\n",
    "    synthconfig=synthconfig,\n",
    "    device=device,\n",
    ")\n",
    "fm_out = fm_vco(keyboard.p(\"midi_f0\"), operator_out)\n",
    "\n",
    "stft_plot(fm_out[0].cpu().detach().numpy())\n",
    "ipd.display(ipd.Audio(fm_out[0].cpu().detach().numpy(), rate=fm_vco.sample_rate.item()))\n",
    "\n",
    "stft_plot(fm_out[1].cpu().detach().numpy())\n",
    "ipd.display(ipd.Audio(fm_out[1].cpu().detach().numpy(), rate=fm_vco.sample_rate.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise\n",
    "\n",
    "The noise generator creates white noise the same length as the SynthModule buffer length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Noise(synthconfig, seed=42, device=device)\n",
    "out = noise()\n",
    "\n",
    "stft_plot(out[0].detach().cpu().numpy())\n",
    "ipd.Audio(out[0].detach().cpu().numpy(), rate=noise.sample_rate.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsynth.module import AudioMixer\n",
    "\n",
    "env = torch.zeros((synthconfig.batch_size, synthconfig.buffer_size), device=device)\n",
    "\n",
    "keyboard = MonophonicKeyboard(synthconfig, device=device)\n",
    "sine = SineVCO(synthconfig, device=device)\n",
    "square_saw = SquareSawVCO(synthconfig, device=device)\n",
    "noise = Noise(synthconfig, seed=123, device=device)\n",
    "\n",
    "midi_f0, note_on_duration = keyboard()\n",
    "sine_out = sine(midi_f0, env)\n",
    "sqr_out = square_saw(midi_f0, env)\n",
    "noise_out = noise()\n",
    "\n",
    "mixer = AudioMixer(synthconfig, 3, curves=[1.0, 1.0, 0.25]).to(device)\n",
    "output = mixer(sine_out, sqr_out, noise_out)\n",
    "\n",
    "ipd.Audio(out[0].cpu().detach().numpy(), rate=mixer.sample_rate.item(), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixer params are set in dB\n",
    "mixer.set_parameter(\"level0\", tensor([0.25, 0.25], device=device))\n",
    "mixer.set_parameter(\"level1\", tensor([0.25, 0.25], device=device))\n",
    "mixer.set_parameter(\"level2\", tensor([0.125, 0.125], device=device))\n",
    "\n",
    "out = mixer(sine_out, sqr_out, noise_out)\n",
    "ipd.Audio(out[0].cpu().detach().numpy(), rate=mixer.sample_rate.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modulation\n",
    "\n",
    "Besides envelopes, LFOs can be used to modulate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsynth.module import LFO, ModulationMixer\n",
    "\n",
    "adsr = ADSR(synthconfig=synthconfig, device=device)\n",
    "\n",
    "# Trigger the keyboard, which returns a midi_f0 and note duration\n",
    "midi_f0, duration = keyboard()\n",
    "\n",
    "envelope = adsr(duration)\n",
    "\n",
    "lfo = LFO(synthconfig, device=device)\n",
    "lfo.set_parameter(\"mod_depth\", tensor([10.0, 0.0]))\n",
    "lfo.set_parameter(\"frequency\", tensor([1.0, 1.0]))\n",
    "out = lfo(envelope)\n",
    "\n",
    "lfo2 = LFO(synthconfig, device=device)\n",
    "out2 = lfo2(envelope)\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "time_plot(out[0].detach().cpu().numpy(), sample_rate=lfo.control_rate.item())\n",
    "time_plot(out2[0].detach().cpu().numpy(), sample_rate=lfo.control_rate.item())\n",
    "\n",
    "# A modulation mixer can be used to mix a modulation sources together\n",
    "# and maintain a 0 to 1 amplitude range\n",
    "mixer = ModulationMixer(synthconfig=synthconfig, device=device, n_input=2, n_output=1)\n",
    "mods_mixed = mixer(out, out2)\n",
    "\n",
    "print(f\"Mixed: LFO 1:{mixer.p('level0_0')[0]:.2}, LFO 2: {mixer.p('level1_0')[0]:.2}\")\n",
    "time_plot(mods_mixed[0][0].detach().cpu().numpy(), sample_rate=lfo.control_rate.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice Module\n",
    "\n",
    "Alternately, you can just use the Voice class that composes all these modules\n",
    "together automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsynth.synth import Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice1 = Voice(synthconfig=synthconfig1).to(device)\n",
    "voice1.set_parameters(\n",
    "    {\n",
    "        (\"keyboard\", \"midi_f0\"): tensor([69.0]),\n",
    "        (\"keyboard\", \"duration\"): tensor([1.0]),\n",
    "        (\"vco_1\", \"tuning\"): tensor([0.0]),\n",
    "        (\"vco_1\", \"mod_depth\"): tensor([12.0]),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "voice_out1 = voice1()\n",
    "stft_plot(voice_out1.cpu().view(-1).detach().numpy())\n",
    "ipd.Audio(voice_out1.cpu().detach().numpy(), rate=voice1.sample_rate.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Additionally, the Voice class can take two oscillators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "voice2 = Voice(synthconfig=synthconfig1).to(device)\n",
    "voice2.set_parameters(\n",
    "    {\n",
    "        (\"keyboard\", \"midi_f0\"): tensor([40.0]),\n",
    "        (\"keyboard\", \"duration\"): tensor([3.0]),\n",
    "        (\"vco_1\", \"tuning\"): tensor([19.0]),\n",
    "        (\"vco_1\", \"mod_depth\"): tensor([24.0]),\n",
    "        (\"vco_2\", \"tuning\"): tensor([0.0]),\n",
    "        (\"vco_2\", \"mod_depth\"): tensor([12.0]),\n",
    "        (\"vco_2\", \"shape\"): tensor([1.0]),\n",
    "    }\n",
    ")\n",
    "\n",
    "voice_out2 = voice2()\n",
    "stft_plot(voice_out2.cpu().view(-1).detach().numpy())\n",
    "ipd.Audio(voice_out2.cpu().detach().numpy(), rate=voice2.sample_rate.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test gradients on entire voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = torch.mean(torch.abs(voice_out1 - voice_out2))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random synths\n",
    "\n",
    "Let's generate some random synths in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthconfig16 = SynthConfig(\n",
    "    batch_size=tensor(16), sample_rate=tensor(44100), buffer_size=tensor(4 * 44100)\n",
    ")\n",
    "voice = Voice(synthconfig=synthconfig16).to(device)\n",
    "voice_out = voice()\n",
    "for i in range(synthconfig16.batch_size):\n",
    "    stft_plot(voice_out[i].cpu().view(-1).detach().numpy())\n",
    "    ipd.display(\n",
    "        ipd.Audio(voice_out[i].cpu().detach().numpy(), rate=voice.sample_rate.item())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters can be set and frozen before randomization as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice.unfreeze_all_parameters()\n",
    "voice.set_frozen_parameters(\n",
    "    {\n",
    "        (\"keyboard\", \"midi_f0\"): 42.0,\n",
    "        (\"keyboard\", \"duration\"): 3.0,\n",
    "        (\"vco_1\", \"tuning\"): 0.0,\n",
    "        (\"vco_2\", \"tuning\"): 0.0,\n",
    "    },\n",
    ")\n",
    "\n",
    "voice_out = voice()\n",
    "for i in range(synthconfig16.batch_size):\n",
    "    stft_plot(voice_out[i].cpu().view(-1).detach().numpy())\n",
    "    ipd.display(\n",
    "        ipd.Audio(voice_out[i].cpu().detach().numpy(), rate=voice.sample_rate.item())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters\n",
    "\n",
    "# All synth modules and synth classes have named parameters which can be quered\n",
    "# and updated. Let's look at the parameters for the Voice we just created.\n",
    "for n, p in voice1.named_parameters():\n",
    "    print(f\"{n:40}\")\n",
    "\n",
    "# Parameters are passed into SynthModules during creation with an initial value and a parameter range. The parameter range is a human readable range of values, for example MIDI note numbers from 1-127 for a VCO. These values are stored in a normalized range between 0 and 1. Parameters can be accessed and set using either ranges with specific methods.\n",
    "#\n",
    "# Parameters of individual modules can be accessed in several ways:\n",
    "\n",
    "# Get the full ModuleParameter object by name from the module\n",
    "print(voice1.vco_1.get_parameter(\"tuning\"))\n",
    "\n",
    "# Access the value as a Tensor in the full value human range\n",
    "print(voice1.vco_1.p(\"tuning\"))\n",
    "\n",
    "# Access the value as a float in the range from 0 to 1\n",
    "print(voice1.vco_1.get_parameter_0to1(\"tuning\"))\n",
    "\n",
    "# Parameters of individual modules can also be set using the human range or a normalized range between 0 and 1\n",
    "\n",
    "# Set the vco pitch using the human range, which is MIDI note number\n",
    "voice1.vco_1.set_parameter(\"tuning\", tensor([12.0]))\n",
    "print(voice1.vco_1.p(\"tuning\"))\n",
    "\n",
    "# Set the vco pitch using a normalized range between 0 and 1\n",
    "voice1.vco_1.set_parameter_0to1(\"tuning\", tensor([0.5]))\n",
    "print(voice1.vco_1.p(\"tuning\"))\n",
    "\n",
    "# #### Parameter Ranges\n",
    "#\n",
    "# Conversion between [0,1] range and a human range is handled by `ModuleParameterRange`. The conversion from [0,1] can be shaped by specifying a curve. Curve values less than 1 put more emphasis on lower values in the human range and curve values greater than 1 put more emphasis on larger values in the human range. A curve of 1 is a linear relationship between the two ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ModuleParameterRange with scaling of a range from 0-127\n",
    "param_range_exp = ModuleParameterRange(0.0, 127.0, curve=0.5)\n",
    "param_range_lin = ModuleParameterRange(0.0, 127.0, curve=1.0)\n",
    "param_range_log = ModuleParameterRange(0.0, 127.0, curve=2.0)\n",
    "\n",
    "# Linearly spaced values from 0.0 1.0\n",
    "param_values = torch.linspace(0.0, 1.0, 100)\n",
    "\n",
    "if isnotebook():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "    axes[0].plot(param_values, param_range_exp.from_0to1(param_values))\n",
    "    axes[0].set_title(\"Exponential Scaling\")\n",
    "\n",
    "    axes[1].plot(param_values, param_range_lin.from_0to1(param_values))\n",
    "    axes[1].set_title(\"Linear Scaling\")\n",
    "\n",
    "    axes[2].plot(param_values, param_range_log.from_0to1(param_values))\n",
    "    axes[2].set_title(\"Logarithmic Scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModuleParameterRange with symmetric scaling of a range from -127 to 127\n",
    "param_range_exp = ModuleParameterRange(-127.0, 127.0, curve=0.5, symmetric=True)\n",
    "param_range_log = ModuleParameterRange(-127.0, 127.0, curve=2.0, symmetric=True)\n",
    "\n",
    "# Linearly spaced values from 0.0 1.0\n",
    "param_values = torch.linspace(0.0, 1.0, 100)\n",
    "\n",
    "if isnotebook():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "    axes[0].plot(param_values, param_range_exp.from_0to1(param_values))\n",
    "    axes[0].set_title(\"Exponential Scaling\")\n",
    "\n",
    "    axes[1].plot(param_values, param_range_log.from_0to1(param_values))\n",
    "    axes[1].set_title(\"Logarithmic Scaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "ParameterRanges are considered hyperparameters in torchsynth and can be viewed and modified through a Synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all hyperparameters\n",
    "voice1.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a specific hyperparameter\n",
    "voice1.set_hyperparameter((\"keyboard\", \"midi_f0\", \"curve\"), 0.1)\n",
    "print(voice1.hyperparameters[(\"keyboard\", \"midi_f0\", \"curve\")])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
